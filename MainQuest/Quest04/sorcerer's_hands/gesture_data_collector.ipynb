{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 필요한 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import Libraries\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import sys # sys.exit() 대신 메시지 출력 후 종료를 위해 사용될 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 전역 설정 및 MediaPipe 모델, 웹캠 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "웹캠이 성공적으로 초기화되었습니다.\n",
      "데이터셋 저장 디렉토리: 'test_dataset'\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Global Setup and Initialization\n",
    "\n",
    "# MediaPipe Hands 모델 초기화\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands(\n",
    "    max_num_hands=2, # 한 번에 감지할 최대 손 개수 (기본값 2개)\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "# 웹캠 초기화 (한 번만 실행)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# 웹캠이 제대로 열렸는지 확인\n",
    "if not cap.isOpened():\n",
    "    print(\"오류: 웹캠을 열 수 없습니다. 웹캠이 연결되어 있고 다른 프로그램에서 사용 중이 아닌지 확인하세요.\")\n",
    "    print(\"이후 셀에서 카메라를 사용하는 함수는 작동하지 않을 수 있습니다.\")\n",
    "    # Jupyter 환경이므로 sys.exit() 대신 메시지 출력 후 진행\n",
    "else:\n",
    "    print(\"웹캠이 성공적으로 초기화되었습니다.\")\n",
    "\n",
    "# 데이터셋을 저장할 디렉토리 생성\n",
    "dataset_dir = 'test_dataset'\n",
    "os.makedirs(dataset_dir, exist_ok=True)\n",
    "print(f\"데이터셋 저장 디렉토리: '{dataset_dir}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 제스처 데이터 수집 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Define Gesture Data Collection Function (for Two Hands)\n",
    "\n",
    "def collect_gesture_data(gesture_name: str, gesture_label_id: int,\n",
    "                         secs_for_action: int = 30, seq_length: int = 30):\n",
    "    \"\"\"\n",
    "    웹캠을 통해 특정 제스처의 데이터를 수집하고 NumPy 파일로 저장합니다.\n",
    "    두 손을 감지하도록 설정되어 있으며, 두 손의 랜드마크 및 각도 데이터를 하나의 프레임으로 저장합니다.\n",
    "    두 손이 모두 감지되지 않으면 해당 프레임은 건너뛸 수 있습니다.\n",
    "\n",
    "    Args:\n",
    "        gesture_name (str): 수집할 제스처의 이름 (예: 'come', 'away', 'spin').\n",
    "        gesture_label_id (int): 해당 제스처에 할당될 숫자 라벨 ID (예: 0, 1, 2).\n",
    "        secs_for_action (int, optional): 각 제스처에 대해 데이터를 수집할 시간(초). 기본값은 30초.\n",
    "        seq_length (int, optional): 시퀀스 데이터 생성 시 하나의 시퀀스에 포함될 프레임 길이. 기본값은 30.\n",
    "    \"\"\"\n",
    "    if not cap.isOpened():\n",
    "        print(f\"경고: 웹캠이 열려 있지 않습니다. '{gesture_name}' 데이터 수집을 건너뜜니다.\")\n",
    "        return\n",
    "\n",
    "    data = [] # 현재 제스처의 원시 데이터를 저장할 리스트\n",
    "    created_time = int(time.time()) # 현재 데이터 수집 세션의 고유 타임스탬프\n",
    "\n",
    "    # 데이터 수집 시작 전 사용자에게 준비 시간 제공\n",
    "    print(f\"\\n--- '{gesture_name.upper()}' 동작 데이터 수집 준비 ---\")\n",
    "    print(\"카메라를 향해 두 손을 준비해주세요.\")\n",
    "\n",
    "    ret, img = cap.read()\n",
    "    if not ret:\n",
    "        print(\"오류: 웹캠에서 프레임을 읽을 수 없습니다. 카메라 연결을 확인하세요.\")\n",
    "        return\n",
    "\n",
    "    img = cv2.flip(img, 1) # 좌우 반전 (거울 모드)\n",
    "    # 수집 대기 메시지 표시\n",
    "    cv2.putText(img, f'Ready for {gesture_name.upper()} in 3 seconds...', org=(10, 30),\n",
    "                fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(0, 255, 0), thickness=2)\n",
    "    cv2.imshow('Gesture Data Collection (Two Hands)', img) # 창 이름 변경\n",
    "    cv2.waitKey(3000) # 3초 대기\n",
    "\n",
    "    start_time = time.time()\n",
    "    print(f\"'{gesture_name.upper()}' 동작 데이터 수집 시작! {secs_for_action}초 동안 동작을 수행해주세요.\")\n",
    "\n",
    "    # 지정된 시간 동안 데이터 수집 루프\n",
    "    while time.time() - start_time < secs_for_action:\n",
    "        ret, img = cap.read()\n",
    "        if not ret:\n",
    "            print(\"오류: 웹캠에서 프레임을 읽을 수 없습니다. 카메라 연결을 확인하세요.\")\n",
    "            break\n",
    "\n",
    "        img = cv2.flip(img, 1) # 좌우 반전\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # MediaPipe 처리를 위해 BGR -> RGB 변환\n",
    "        result = hands.process(img) # MediaPipe를 이용한 손 랜드마크 감지\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) # OpenCV 표시를 위해 RGB -> BGR 변환\n",
    "\n",
    "        if result.multi_hand_landmarks and len(result.multi_hand_landmarks) == 2:\n",
    "            # ***두 손이 모두 감지된 경우에만 데이터를 처리***\n",
    "            # 만약 한 손만 감지되더라도 처리하고 싶다면, 이 조건을 제거하고\n",
    "            # 각 손의 데이터를 빈 배열로 채우는 로직을 추가해야 합니다.\n",
    "            # (예: np.zeros(size)를 사용하여 감지되지 않은 손의 데이터를 채움)\n",
    "\n",
    "            # 왼쪽/오른쪽 손을 식별하고 순서를 맞추는 로직 (선택 사항, 필요 시 추가)\n",
    "            # 여기서는 단순히 감지된 두 손을 순서대로 처리합니다.\n",
    "            # 랜드마크 0번(손목)의 x좌표를 기준으로 왼쪽/오른쪽을 구분할 수 있습니다.\n",
    "            handedness = [(lm.landmark[0].x, i) for i, lm in enumerate(result.multi_hand_landmarks)]\n",
    "            handedness.sort() # x좌표를 기준으로 정렬 (왼쪽 손부터)\n",
    "\n",
    "            combined_hand_data = []\n",
    "\n",
    "            for _, hand_idx in handedness: # 정렬된 순서로 각 손 처리\n",
    "                res = result.multi_hand_landmarks[hand_idx]\n",
    "\n",
    "                # 21개 손 랜드마크의 x, y, z 좌표 및 가시성(visibility) 추출\n",
    "                joint = np.zeros((21, 4))\n",
    "                for j, lm in enumerate(res.landmark):\n",
    "                    joint[j] = [lm.x, lm.y, lm.z, lm.visibility]\n",
    "\n",
    "                # 관절 사이의 벡터 계산 (부모-자식 관절 쌍)\n",
    "                v1 = joint[[0,1,2,3,0,5,6,7,0,9,10,11,0,13,14,15,0,17,18,19], :3] # Parent joint\n",
    "                v2 = joint[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20], :3] # Child joint\n",
    "                v = v2 - v1 # 벡터 (20, 3)\n",
    "\n",
    "                # 벡터 정규화 (길이를 1로 만듦)\n",
    "                norm_v = np.linalg.norm(v, axis=1)\n",
    "                v = v / (norm_v[:, np.newaxis] + 1e-8) # 0으로 나누는 오류 방지\n",
    "\n",
    "                # 두 벡터 사이의 각도 계산 (내적을 이용)\n",
    "                dot_product = np.einsum('nt,nt->n',\n",
    "                                         v[[0,1,2,4,5,6,8,9,10,12,13,14,16,17,18],:],\n",
    "                                         v[[1,2,3,5,6,7,9,10,11,13,14,15,17,18,19],:])\n",
    "                dot_product = np.clip(dot_product, -1.0, 1.0) # arccos의 도메인 클리핑\n",
    "\n",
    "                angle = np.arccos(dot_product) # 라디안 각도 (15,)\n",
    "                angle = np.degrees(angle) # 라디안을 도로 변환\n",
    "\n",
    "                # 각 손의 랜드마크 및 각도 데이터 추가\n",
    "                # 두 손의 데이터를 하나의 벡터로 만듭니다.\n",
    "                # (21 * 4) 랜드마크 + 15 각도 = 84 + 15 = 99\n",
    "                combined_hand_data.append(joint.flatten()) # 손 랜드마크 84개\n",
    "                combined_hand_data.append(angle)           # 손 각도 15개\n",
    "\n",
    "                mp_drawing.draw_landmarks(img, res, mp_hands.HAND_CONNECTIONS) # 화면에 그리기\n",
    "\n",
    "            # 두 손의 데이터(랜드마크 + 각도 + 랜드마크 + 각도)에 제스처 라벨 ID 추가\n",
    "            # 최종 데이터 구조: [손1_랜드마크(84), 손1_각도(15), 손2_랜드마크(84), 손2_각도(15), 제스처_ID(1)]\n",
    "            # 총 84 + 15 + 84 + 15 + 1 = 199개 데이터 포인트\n",
    "            d = np.concatenate(combined_hand_data + [np.array([gesture_label_id])]).astype(np.float32)\n",
    "            data.append(d) # 수집된 데이터를 리스트에 추가\n",
    "        else:\n",
    "            # 두 손이 모두 감지되지 않은 프레임은 건너뜁니다.\n",
    "            # 필요에 따라 이곳에 빈 데이터를 추가하거나 경고를 출력할 수 있습니다.\n",
    "            pass # print(\"경고: 두 손이 모두 감지되지 않았습니다.\")\n",
    "\n",
    "\n",
    "        # 화면에 현재 동작 및 남은 시간 표시\n",
    "        elapsed_time = int(time.time() - start_time)\n",
    "        remaining_time = max(0, secs_for_action - elapsed_time)\n",
    "        cv2.putText(img, f'{gesture_name.upper()}: {remaining_time}s left (Two Hands)', org=(10, 30),\n",
    "                    fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(255, 255, 255), thickness=2)\n",
    "        cv2.imshow('Gesture Data Collection (Two Hands)', img)\n",
    "\n",
    "        # 'q' 키를 누르면 수집 중단\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            print(\"사용자 요청으로 데이터 수집을 중단합니다.\")\n",
    "            break # 내부 루프 종료\n",
    "\n",
    "    # 데이터 저장\n",
    "    if len(data) > 0:\n",
    "        data = np.array(data)\n",
    "        print(f\"'{gesture_name}' raw 데이터 shape: {data.shape}\")\n",
    "        raw_filename = os.path.join(dataset_dir, f'raw_{gesture_name}_{created_time}.npy')\n",
    "        np.save(raw_filename, data)\n",
    "        print(f\"'{gesture_name}' raw 데이터가 저장되었습니다: {raw_filename}\")\n",
    "\n",
    "        # 시퀀스 데이터 생성 및 저장\n",
    "        full_seq_data = []\n",
    "        if len(data) >= seq_length:\n",
    "            for seq in range(len(data) - seq_length + 1):\n",
    "                full_seq_data.append(data[seq:seq + seq_length])\n",
    "\n",
    "        if len(full_seq_data) > 0:\n",
    "            full_seq_data = np.array(full_seq_data)\n",
    "            print(f\"'{gesture_name}' sequence 데이터 shape: {full_seq_data.shape}\")\n",
    "            seq_filename = os.path.join(dataset_dir, f'seq_{gesture_name}_{created_time}.npy')\n",
    "            np.save(seq_filename, full_seq_data)\n",
    "            print(f\"'{gesture_name}' sequence 데이터가 저장되었습니다: {seq_filename}\")\n",
    "        else:\n",
    "            print(f\"경고: '{gesture_name}' 시퀀스 데이터를 생성할 충분한 데이터가 없습니다.\")\n",
    "            print(f\"  (수집된 프레임: {len(data)}, 필요한 시퀀스 길이: {seq_length})\")\n",
    "    else:\n",
    "        print(f\"'{gesture_name}'에 대해 수집된 데이터가 없습니다.\")\n",
    "\n",
    "    print(f\"--- '{gesture_name.upper()}' 데이터 수집 완료 ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 함수 사용 예시 (데이터 수집 실행)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 'FLOWER' 동작 데이터 수집 준비 ---\n",
      "카메라를 향해 두 손을 준비해주세요.\n",
      "'FLOWER' 동작 데이터 수집 시작! 60초 동안 동작을 수행해주세요.\n",
      "'flower' raw 데이터 shape: (1055, 199)\n",
      "'flower' raw 데이터가 저장되었습니다: test_dataset\\raw_flower_1750301079.npy\n",
      "'flower' sequence 데이터 shape: (1026, 30, 199)\n",
      "'flower' sequence 데이터가 저장되었습니다: test_dataset\\seq_flower_1750301079.npy\n",
      "--- 'FLOWER' 데이터 수집 완료 ---\n",
      "\n",
      "--- 'CROWN' 동작 데이터 수집 준비 ---\n",
      "카메라를 향해 두 손을 준비해주세요.\n",
      "'CROWN' 동작 데이터 수집 시작! 60초 동안 동작을 수행해주세요.\n",
      "'crown' raw 데이터 shape: (631, 199)\n",
      "'crown' raw 데이터가 저장되었습니다: test_dataset\\raw_crown_1750301143.npy\n",
      "'crown' sequence 데이터 shape: (602, 30, 199)\n",
      "'crown' sequence 데이터가 저장되었습니다: test_dataset\\seq_crown_1750301143.npy\n",
      "--- 'CROWN' 데이터 수집 완료 ---\n",
      "\n",
      "--- 'HEARTBEAT' 동작 데이터 수집 준비 ---\n",
      "카메라를 향해 두 손을 준비해주세요.\n",
      "'HEARTBEAT' 동작 데이터 수집 시작! 60초 동안 동작을 수행해주세요.\n",
      "'heartbeat' raw 데이터 shape: (1036, 199)\n",
      "'heartbeat' raw 데이터가 저장되었습니다: test_dataset\\raw_heartbeat_1750301206.npy\n",
      "'heartbeat' sequence 데이터 shape: (1007, 30, 199)\n",
      "'heartbeat' sequence 데이터가 저장되었습니다: test_dataset\\seq_heartbeat_1750301206.npy\n",
      "--- 'HEARTBEAT' 데이터 수집 완료 ---\n",
      "\n",
      "--- 'FIREWORK' 동작 데이터 수집 준비 ---\n",
      "카메라를 향해 두 손을 준비해주세요.\n",
      "'FIREWORK' 동작 데이터 수집 시작! 60초 동안 동작을 수행해주세요.\n",
      "'firework' raw 데이터 shape: (847, 199)\n",
      "'firework' raw 데이터가 저장되었습니다: test_dataset\\raw_firework_1750301269.npy\n",
      "'firework' sequence 데이터 shape: (818, 30, 199)\n",
      "'firework' sequence 데이터가 저장되었습니다: test_dataset\\seq_firework_1750301269.npy\n",
      "--- 'FIREWORK' 데이터 수집 완료 ---\n",
      "\n",
      "--- 'BEAR' 동작 데이터 수집 준비 ---\n",
      "카메라를 향해 두 손을 준비해주세요.\n",
      "'BEAR' 동작 데이터 수집 시작! 60초 동안 동작을 수행해주세요.\n",
      "'bear' raw 데이터 shape: (584, 199)\n",
      "'bear' raw 데이터가 저장되었습니다: test_dataset\\raw_bear_1750301332.npy\n",
      "'bear' sequence 데이터 shape: (555, 30, 199)\n",
      "'bear' sequence 데이터가 저장되었습니다: test_dataset\\seq_bear_1750301332.npy\n",
      "--- 'BEAR' 데이터 수집 완료 ---\n",
      "\n",
      "--- 'CAT' 동작 데이터 수집 준비 ---\n",
      "카메라를 향해 두 손을 준비해주세요.\n",
      "'CAT' 동작 데이터 수집 시작! 60초 동안 동작을 수행해주세요.\n",
      "'cat' raw 데이터 shape: (695, 199)\n",
      "'cat' raw 데이터가 저장되었습니다: test_dataset\\raw_cat_1750301396.npy\n",
      "'cat' sequence 데이터 shape: (666, 30, 199)\n",
      "'cat' sequence 데이터가 저장되었습니다: test_dataset\\seq_cat_1750301396.npy\n",
      "--- 'CAT' 데이터 수집 완료 ---\n",
      "\n",
      "--- 'GUN' 동작 데이터 수집 준비 ---\n",
      "카메라를 향해 두 손을 준비해주세요.\n",
      "'GUN' 동작 데이터 수집 시작! 60초 동안 동작을 수행해주세요.\n",
      "'gun' raw 데이터 shape: (1119, 199)\n",
      "'gun' raw 데이터가 저장되었습니다: test_dataset\\raw_gun_1750301459.npy\n",
      "'gun' sequence 데이터 shape: (1090, 30, 199)\n",
      "'gun' sequence 데이터가 저장되었습니다: test_dataset\\seq_gun_1750301459.npy\n",
      "--- 'GUN' 데이터 수집 완료 ---\n",
      "\n",
      "--- 'HEART_ON_THE_CHEEK' 동작 데이터 수집 준비 ---\n",
      "카메라를 향해 두 손을 준비해주세요.\n",
      "'HEART_ON_THE_CHEEK' 동작 데이터 수집 시작! 60초 동안 동작을 수행해주세요.\n",
      "'heart_on_the_cheek' raw 데이터 shape: (580, 199)\n",
      "'heart_on_the_cheek' raw 데이터가 저장되었습니다: test_dataset\\raw_heart_on_the_cheek_1750301522.npy\n",
      "'heart_on_the_cheek' sequence 데이터 shape: (551, 30, 199)\n",
      "'heart_on_the_cheek' sequence 데이터가 저장되었습니다: test_dataset\\seq_heart_on_the_cheek_1750301522.npy\n",
      "--- 'HEART_ON_THE_CHEEK' 데이터 수집 완료 ---\n",
      "\n",
      "--- 'SON_CELEBRATION' 동작 데이터 수집 준비 ---\n",
      "카메라를 향해 두 손을 준비해주세요.\n",
      "'SON_CELEBRATION' 동작 데이터 수집 시작! 60초 동안 동작을 수행해주세요.\n",
      "'son_celebration' raw 데이터 shape: (1073, 199)\n",
      "'son_celebration' raw 데이터가 저장되었습니다: test_dataset\\raw_son_celebration_1750301585.npy\n",
      "'son_celebration' sequence 데이터 shape: (1044, 30, 199)\n",
      "'son_celebration' sequence 데이터가 저장되었습니다: test_dataset\\seq_son_celebration_1750301585.npy\n",
      "--- 'SON_CELEBRATION' 데이터 수집 완료 ---\n",
      "\n",
      "--- 'TIGER' 동작 데이터 수집 준비 ---\n",
      "카메라를 향해 두 손을 준비해주세요.\n",
      "'TIGER' 동작 데이터 수집 시작! 60초 동안 동작을 수행해주세요.\n",
      "'tiger' raw 데이터 shape: (924, 199)\n",
      "'tiger' raw 데이터가 저장되었습니다: test_dataset\\raw_tiger_1750301648.npy\n",
      "'tiger' sequence 데이터 shape: (895, 30, 199)\n",
      "'tiger' sequence 데이터가 저장되었습니다: test_dataset\\seq_tiger_1750301648.npy\n",
      "--- 'TIGER' 데이터 수집 완료 ---\n",
      "\n",
      "--- 'PIPE' 동작 데이터 수집 준비 ---\n",
      "카메라를 향해 두 손을 준비해주세요.\n",
      "'PIPE' 동작 데이터 수집 시작! 60초 동안 동작을 수행해주세요.\n",
      "'pipe' raw 데이터 shape: (1168, 199)\n",
      "'pipe' raw 데이터가 저장되었습니다: test_dataset\\raw_pipe_1750301711.npy\n",
      "'pipe' sequence 데이터 shape: (1139, 30, 199)\n",
      "'pipe' sequence 데이터가 저장되었습니다: test_dataset\\seq_pipe_1750301711.npy\n",
      "--- 'PIPE' 데이터 수집 완료 ---\n",
      "\n",
      "--- 'LANDMARKS' 동작 데이터 수집 준비 ---\n",
      "카메라를 향해 두 손을 준비해주세요.\n",
      "'LANDMARKS' 동작 데이터 수집 시작! 60초 동안 동작을 수행해주세요.\n",
      "'landmarks' raw 데이터 shape: (1058, 199)\n",
      "'landmarks' raw 데이터가 저장되었습니다: test_dataset\\raw_landmarks_1750301774.npy\n",
      "'landmarks' sequence 데이터 shape: (1029, 30, 199)\n",
      "'landmarks' sequence 데이터가 저장되었습니다: test_dataset\\seq_landmarks_1750301774.npy\n",
      "--- 'LANDMARKS' 데이터 수집 완료 ---\n",
      "\n",
      "--- 'SUMI' 동작 데이터 수집 준비 ---\n",
      "카메라를 향해 두 손을 준비해주세요.\n",
      "'SUMI' 동작 데이터 수집 시작! 60초 동안 동작을 수행해주세요.\n",
      "'sumi' raw 데이터 shape: (1049, 199)\n",
      "'sumi' raw 데이터가 저장되었습니다: test_dataset\\raw_sumi_1750301837.npy\n",
      "'sumi' sequence 데이터 shape: (1020, 30, 199)\n",
      "'sumi' sequence 데이터가 저장되었습니다: test_dataset\\seq_sumi_1750301837.npy\n",
      "--- 'SUMI' 데이터 수집 완료 ---\n",
      "\n",
      "모든 지정된 제스처에 대한 데이터 수집이 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Example Usage - Collect Data for Defined Gestures\n",
    "\n",
    "# 수집할 제스처 목록과 해당 라벨 ID 정의\n",
    "# 모델 학습 시 이 라벨 ID를 사용하여 각 제스처를 분류합니다.\n",
    "gestures_to_collect = [\n",
    "    {'name': 'flower', 'label_id': 0},\n",
    "    {'name': 'crown', 'label_id': 1},\n",
    "    {'name': 'heartbeat', 'label_id': 2},\n",
    "    {'name': 'firework', 'label_id': 3},\n",
    "    {'name': 'bear', 'label_id': 4},\n",
    "    {'name': 'cat', 'label_id': 5},\n",
    "    {'name': 'gun', 'label_id': 6},\n",
    "    {'name': 'heart_on_the_cheek', 'label_id': 7},\n",
    "    {'name': 'son_celebration', 'label_id': 8},\n",
    "    {'name': 'tiger', 'label_id': 9},\n",
    "    {'name': 'pipe', 'label_id': 10},\n",
    "    {'name': 'landmarks', 'label_id': 11},\n",
    "    #{'name': 'sumi', 'label_id': 12},\n",
    "    # 필요한 경우 여기에 더 많은 제스처를 추가하세요.\n",
    "]\n",
    "\n",
    "# 각 제스처에 대해 데이터 수집 함수 호출\n",
    "for gesture_info in gestures_to_collect:\n",
    "    collect_gesture_data(\n",
    "        gesture_name=gesture_info['name'],\n",
    "        gesture_label_id=gesture_info['label_id'],\n",
    "        secs_for_action=60, # 각 제스처당 30초 수집\n",
    "        seq_length=30      # 시퀀스 길이 30프레임\n",
    "    )\n",
    "\n",
    "print(\"\\n모든 지정된 제스처에 대한 데이터 수집이 완료되었습니다.\")\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 리소스 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "웹캠 리소스가 해제되었습니다.\n",
      "모든 OpenCV 창이 닫혔습니다.\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Cleanup Resources\n",
    "\n",
    "# 웹캠 리소스 해제\n",
    "if cap.isOpened():\n",
    "    cap.release()\n",
    "    print(\"웹캠 리소스가 해제되었습니다.\")\n",
    "\n",
    "# 모든 OpenCV 창 닫기\n",
    "cv2.destroyAllWindows()\n",
    "print(\"모든 OpenCV 창이 닫혔습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "miniaiffel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
